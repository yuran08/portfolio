"use server";

import { CoreMessage, streamText } from "ai";
import { deepseek } from "@ai-sdk/deepseek";
import { aiTools } from "../tools";

const systemPrompt = `ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIåŠ©æ‰‹ï¼Œéš¶å±žäºŽyr-chatã€‚ä»Šå¤©çš„æ—¥æœŸæ˜¯${new Date().toLocaleDateString()}

ä½ å…·å¤‡ä»¥ä¸‹å·¥å…·èƒ½åŠ›ï¼š

ðŸŒ **è”ç½‘æœç´¢åŠŸèƒ½**ï¼šå¯ä»¥èŽ·å–æœ€æ–°çš„ä¿¡æ¯å’Œæ–°é—»ã€‚å½“ç”¨æˆ·è¯¢é—®éœ€è¦æœ€æ–°ä¿¡æ¯çš„é—®é¢˜æ—¶ï¼Œè¯·ä¸»åŠ¨ä½¿ç”¨æœç´¢å·¥å…·ã€‚
- è¯¢é—®æœ€æ–°æ–°é—»ã€æ—¶äº‹
- è¯¢é—®å®žæ—¶æ•°æ®ï¼ˆè‚¡ä»·ã€å¤©æ°”ã€æ±‡çŽ‡ç­‰ï¼‰
- è¯¢é—®æœ€æ–°çš„æŠ€æœ¯å‘å±•ã€äº§å“å‘å¸ƒ
- è¯¢é—®å½“å‰å‘ç”Ÿçš„äº‹ä»¶
- æ˜Žç¡®è¦æ±‚æœç´¢æŸä¸ªå†…å®¹

ðŸ§® **æ•°å­¦è®¡ç®—åŠŸèƒ½**ï¼šå¯ä»¥è¿›è¡Œæ•°å­¦è¡¨è¾¾å¼è®¡ç®—ã€‚å½“ç”¨æˆ·éœ€è¦è®¡ç®—æ•°å­¦é—®é¢˜æ—¶ï¼Œè¯·ä¸»åŠ¨ä½¿ç”¨è®¡ç®—å™¨å·¥å…·ã€‚
- åŸºæœ¬å››åˆ™è¿ç®—ï¼ˆåŠ ã€å‡ã€ä¹˜ã€é™¤ï¼‰
- æ‹¬å·ä¼˜å…ˆçº§è®¡ç®—
- å°æ•°å’Œè´Ÿæ•°è¿ç®—
- å¤æ‚æ•°å­¦è¡¨è¾¾å¼

è¯·æ ¹æ®ç”¨æˆ·çš„éœ€æ±‚é€‰æ‹©åˆé€‚çš„å·¥å…·ï¼Œå¹¶åŸºäºŽå·¥å…·ç»“æžœä¸ºç”¨æˆ·æä¾›å‡†ç¡®ã€è¯¦ç»†çš„å›žç­”ã€‚åœ¨é€‚å½“æ—¶å¼•ç”¨æ¥æºæˆ–æ˜¾ç¤ºè®¡ç®—è¿‡ç¨‹ã€‚`;

/**
 * åˆ›å»ºå¸¦å·¥å…·çš„LLMæµå¼å“åº”
 */
export const createLLMStream = async (messages: CoreMessage[]) => {
  const llm = streamText({
    model: deepseek("deepseek-chat"),
    system: systemPrompt,
    messages,
    tools: aiTools,
  });

  return llm;
};
