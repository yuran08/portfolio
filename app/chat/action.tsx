"use server";

import db from "@/lib/redis";
import {
  UserMessageWrapper,
  AssistantMessageWrapper,
  ToolMessageWrapper,
} from "./components/message";
import { Suspense, ReactNode } from "react";
import { revalidatePath } from "next/cache";
import { Message } from "./type";
import ParseLLMReaderToMarkdownGenerator from "./lib/parser";
import { LoadingWithText, ErrorText } from "./components/skeleton";
import { createLLMStream } from "./lib/llm";
import { CoreMessage, ToolResultPart } from "ai";
import GetNextResponse from "./get-next-response";
import { BaseToolResult, formatToolResult } from "./tools";
import { MemoizedMarkdown } from "./components/markdown";
import StreamHandler from "./components/stream-handler";

// å¼€å§‹å¯¹è¯
export const startConversation = async (
  conversationId: string,
  message: string
) => {
  await db.conversation.create({
    id: conversationId,
    title: message,
  });

  await db.message.create({
    content: message,
    role: "user",
    conversationId,
  });
};

// æ›´æ–°å¯¹è¯æ ‡é¢˜
export const updateConversationTitle = async (
  conversationId: string,
  title: string
) => {
  await db.conversation.update(conversationId, { title });
  revalidatePath(`/chat`);
};

// åˆ é™¤å¯¹è¯
export const deleteConversation = async (conversationId: string) => {
  await db.conversation.delete(conversationId);
  revalidatePath(`/chat`);
  revalidatePath(`/chat/conversation/${conversationId}`);
};

// æ·»åŠ æ¶ˆæ¯
export const conversationAddMessage = async (
  conversationId: string,
  message: string
): Promise<ReactNode> => {
  await db.message.create({
    content: message,
    role: "user",
    conversationId,
  });
  const messages = await db.message.findByConversationId(conversationId);

  const llmResponseReactNode = await getLLMResponseReactNode(
    conversationId,
    messages
  );

  revalidatePath(`/chat/conversation/${conversationId}`, "layout");
  return llmResponseReactNode;
};

// è·å–å¯¹è¯åˆ—è¡¨
export const getConversationList = async () => {
  const conversations = await db.conversation.findMany();
  return conversations;
};

// æ ¹æ®æ¶ˆæ¯ç”ŸæˆLLMå“åº”çš„ReactèŠ‚ç‚¹
export const getLLMResponseReactNode = async (
  conversationId: string,
  messages: Message[]
): Promise<ReactNode> => {
  const { textStream, toolCalls, toolResults } = await createLLMStream(
    messages as CoreMessage[],
    conversationId
  );
  const llmReader = textStream.getReader();
  const llmGenerator = ParseLLMReaderToMarkdownGenerator(llmReader);

  const wrappedToolResults = createPromiseWithStatus(toolResults);

  const { done: hasToolCall, value: firstChunck } = await llmGenerator.next();

  const StreamWithToolCalls = async () => {
    const streamToolCalls = await toolCalls;

    await db.message.create({
      content: JSON.stringify(streamToolCalls),
      role: "assistant",
      conversationId,
    });

    const toolName = streamToolCalls[0].toolName;

    // é€’å½’å¤„ç†å·¥å…·è°ƒç”¨ç»“æœ
    const ProcessToolResults = async () => {
      if (wrappedToolResults.isPending) {
        return (
          <Suspense
            fallback={
              <ToolMessageWrapper>
                <LoadingWithText text={`ğŸ”§æ­£åœ¨æ‰§è¡Œ ${toolName} å·¥å…·...`} />
              </ToolMessageWrapper>
            }
          >
            <ProcessToolResults />
          </Suspense>
        );
      }

      if (wrappedToolResults.isFulfilled) {
        const result = await wrappedToolResults.wrappedPromise;
        const llmResponseReactNode = await addToolResultForNextMessage(
          conversationId,
          result
        );
        return llmResponseReactNode;
      }

      return (
        <ToolMessageWrapper>
          <ErrorText text={`å·¥å…·è°ƒç”¨å¤±è´¥: ${toolName}`} />
        </ToolMessageWrapper>
      );
    };

    return <ProcessToolResults />;
  };

  return (
    <>
      <UserMessageWrapper>
        {messages[messages.length - 1].content as string}
      </UserMessageWrapper>
      {hasToolCall ? (
        <Suspense
          fallback={
            <ToolMessageWrapper>
              <LoadingWithText text={`ğŸ”§æ­£åœ¨è¯†åˆ«å·¥å…·è°ƒç”¨...`} />
            </ToolMessageWrapper>
          }
        >
          <StreamWithToolCalls />
        </Suspense>
      ) : (
        <AssistantMessageWrapper>
          <Suspense fallback={<LoadingWithText text="AI æ­£åœ¨æ€è€ƒ..." />}>
            <StreamHandler
              generator={llmGenerator}
              conversationId={conversationId}
              initialContent={firstChunck}
            />
          </Suspense>
        </AssistantMessageWrapper>
      )}
    </>
  );
};

// è·å–å·¥å…·è°ƒç”¨ç»“æœ
export const addToolResultForNextMessage = async (
  conversationId: string,
  content: Message["content"]
) => {
  // æ£€æŸ¥å·¥å…·æ˜¯å¦éœ€è¦AIè¿›ä¸€æ­¥å¤„ç†ç»“æœ
  let requiresFollowUp = true;

  // æå–renderDataå­—æ®µè¿›è¡Œå­˜å‚¨ï¼Œå‡å°‘æ•°æ®åº“å†…å­˜å‹åŠ›
  const extractRenderData = (toolResults: ToolResultPart[]) => {
    return toolResults.map((toolResult) => {
      const result = toolResult.result as BaseToolResult;

      // æ£€æŸ¥å·¥å…·æ˜¯å¦éœ€è¦AIåç»­å¤„ç†
      // å½“å‰æœ€å¤šåªæœ‰ä¸€ä¸ªtoolcallï¼Œè‹¥å¢åŠ å¤šä¸ªéœ€è¦ä¿®æ”¹åˆ¤æ–­é€»è¾‘
      if (result.requiresFollowUp === false) {
        requiresFollowUp = false;
      }

      return {
        type: toolResult.type,
        toolCallId: toolResult.toolCallId,
        toolName: toolResult.toolName,
        result: result.renderData, // åªå­˜å‚¨æ¸²æŸ“å¿…è¦çš„æ•°æ®
      };
    });
  };

  const optimizedContent = extractRenderData(content as ToolResultPart[]);

  await db.message.create({
    content: JSON.stringify(optimizedContent),
    role: "tool",
    conversationId,
  });

  // å¦‚æœå·¥å…·ä¸éœ€è¦AIè¿›ä¸€æ­¥å¤„ç†ï¼Œç›´æ¥è¿”å›å·¥å…·ç»“æœ
  if (!requiresFollowUp) {
    return (
      <>
        <ToolMessageWrapper>
          <MemoizedMarkdown
            id={(content as ToolResultPart[])[0].toolCallId}
            content={formatToolResult(
              (content as ToolResultPart[])[0].toolName,
              (content as ToolResultPart[])[0].result
            )}
          />
        </ToolMessageWrapper>
      </>
    );
  }

  const messages = (await db.message.findByConversationId(conversationId)).map(
    (message) => ({
      id: message.id,
      role: message.role,
      content: message.content,
    })
  );
  const llm = await createLLMStream(messages as CoreMessage[], conversationId);
  const llmReader = llm.textStream.getReader();
  const llmGenerator = ParseLLMReaderToMarkdownGenerator(llmReader);

  return (
    <>
      <ToolMessageWrapper>
        <MemoizedMarkdown
          id={(content as ToolResultPart[])[0].toolCallId}
          content={formatToolResult(
            (content as ToolResultPart[])[0].toolName,
            (content as ToolResultPart[])[0].result
          )}
        />
      </ToolMessageWrapper>
      <AssistantMessageWrapper>
        <Suspense fallback={<LoadingWithText text="æ­£åœ¨ç­‰å¾…å·¥å…·è°ƒç”¨ç»“æœ..." />}>
          <StreamHandler
            generator={llmGenerator}
            conversationId={conversationId}
          />
        </Suspense>
      </AssistantMessageWrapper>
    </>
  );
};

// è·å–åˆå§‹å¯¹è¯çš„ReactèŠ‚ç‚¹
export const getInitConversationReactNode = async (conversationId: string) => {
  const messages = await db.message.findByConversationId(conversationId);

  if (messages.length === 0)
    return (
      <div
        key={conversationId}
        className="flex h-full items-center justify-center"
      >
        <p>æœªæ‰¾åˆ°å½“å‰å¯¹è¯</p>
      </div>
    );

  if (messages.length === 1)
    return (
      <GetNextResponse
        key={conversationId}
        conversationId={conversationId}
        messages={messages}
      />
    );

  return (
    <>
      {messages.map((message) => {
        if (message.role === "user") {
          return (
            <UserMessageWrapper key={message.id}>
              {message.content as string}
            </UserMessageWrapper>
          );
        }

        if (
          message.role === "assistant" &&
          typeof message.content === "string"
        ) {
          return (
            <AssistantMessageWrapper key={message.id}>
              <MemoizedMarkdown
                id={message.id}
                content={message.content || "## ç³»ç»Ÿé”™è¯¯ï¼Œè¯·é‡è¯•"}
              />
            </AssistantMessageWrapper>
          );
        }

        // å¤„ç†å·¥å…·æ¶ˆæ¯
        if (message.role === "tool") {
          const tools = message.content as unknown as ToolResultPart[];

          // åªæœ‰å½“æœ‰å·¥å…·ç»“æœæ—¶æ‰æ¸²æŸ“ ToolMessageWrapper
          if (tools.length > 0) {
            return (
              <ToolMessageWrapper key={message.id}>
                {tools.map((item, index) => (
                  <MemoizedMarkdown
                    key={`${item.toolName}-${index}`}
                    id={message.id}
                    content={formatToolResult(item.toolName, item.result)}
                  />
                ))}
              </ToolMessageWrapper>
            );
          }
        }

        // å¦‚æœæ²¡æœ‰åŒ¹é…çš„ç±»å‹ï¼Œè¿”å› null
        return null;
      })}
    </>
  );
};

function createPromiseWithStatus<T>(promise: Promise<T>) {
  let status = "pending";

  const wrappedPromise = promise.then(
    (value) => {
      status = "fulfilled";
      return value;
    },
    (error) => {
      status = "rejected";
      throw error;
    }
  );

  return {
    get isPending() {
      return status === "pending";
    },
    get isFulfilled() {
      return status === "fulfilled";
    },
    get isRejected() {
      return status === "rejected";
    },
    wrappedPromise,
  };
}
